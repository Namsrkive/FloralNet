{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#ğŸŒ¸ Flower Species Classification Using CNN (Oxford Flowers Dataset)"
      ],
      "metadata": {
        "id": "F7q5SzM770W9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ğŸ“¥Step 1: Unzip the file"
      ],
      "metadata": {
        "id": "QIh7xfqQ8QXY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Path to the uploaded zip file\n",
        "zip_file_path = '/content/flower_dataset.zip'\n",
        "\n",
        "# Extract the zip file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/flower_dataset')\n",
        "\n",
        "# Verify the files were extracted\n",
        "extracted_files = os.listdir('/content/flower_dataset')\n",
        "print(extracted_files)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ZVtfUiHd8DWh",
        "outputId": "8460838d-65b2-43c9-ce02-383f4810d878"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['sample_submission.csv', 'cat_to_name.json', 'dataset', 'README.md']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "dataset_path = '/content/flower_dataset/dataset'\n",
        "classes = os.listdir(dataset_path)\n",
        "print(classes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "JjI_wE65Gwuw",
        "outputId": "372d87b0-3a31-4f53-a069-19ac41074977"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['valid', 'train', 'test']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Import Required Libraries\n",
        "First, let's import the necessary libraries. We will be using TensorFlow and Keras for constructing the model, as well as libraries like NumPy and Matplotlib for data handling and visualization."
      ],
      "metadata": {
        "id": "OhbOrPXlBL1G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import json\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, regularizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from tensorflow.keras.layers import LeakyReLU"
      ],
      "metadata": {
        "id": "aFLl0eKTBK2y"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ğŸ§¹Step 3: Setup Paths\n",
        "Define the paths where your dataset and other required files are located.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bTKU5dRTBjp-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = '/content/flower_dataset/dataset'  # Path where your dataset is located\n",
        "train_dir = os.path.join(base_path, 'train')\n",
        "valid_dir = os.path.join(base_path, 'valid')\n",
        "test_dir = os.path.join(base_path, 'test')\n",
        "\n",
        "json_path = '/content/flower_dataset/cat_to_name.json'  # Path to the cat_to_name.json file\n"
      ],
      "metadata": {
        "id": "3hxV554ABrf4"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: Load the cat_to_name Mapping\n",
        "In this step, we load the cat_to_name.json file which maps the class IDs to the actual flower names."
      ],
      "metadata": {
        "id": "tFfIv46RB0cv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(json_path, 'r') as f:\n",
        "    cat_to_name = json.load(f)\n",
        "\n",
        "# Optional: convert keys to int if needed\n",
        "cat_to_name = {int(k): v for k, v in cat_to_name.items()}\n",
        "print(cat_to_name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "lQjQDv90B5ty",
        "outputId": "8340b3ee-3015-4a1a-9002-1c9a87add70c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{21: 'fire lily', 3: 'canterbury bells', 45: 'bolero deep blue', 1: 'pink primrose', 34: 'mexican aster', 27: 'prince of wales feathers', 7: 'moon orchid', 16: 'globe-flower', 25: 'grape hyacinth', 26: 'corn poppy', 79: 'toad lily', 39: 'siam tulip', 24: 'red ginger', 67: 'spring crocus', 35: 'alpine sea holly', 32: 'garden phlox', 10: 'globe thistle', 6: 'tiger lily', 93: 'ball moss', 33: 'love in the mist', 9: 'monkshood', 102: 'blackberry lily', 14: 'spear thistle', 19: 'balloon flower', 100: 'blanket flower', 13: 'king protea', 49: 'oxeye daisy', 15: 'yellow iris', 61: 'cautleya spicata', 31: 'carnation', 64: 'silverbush', 68: 'bearded iris', 63: 'black-eyed susan', 69: 'windflower', 62: 'japanese anemone', 20: 'giant white arum lily', 38: 'great masterwort', 4: 'sweet pea', 86: 'tree mallow', 101: 'trumpet creeper', 42: 'daffodil', 22: 'pincushion flower', 2: 'hard-leaved pocket orchid', 54: 'sunflower', 66: 'osteospermum', 70: 'tree poppy', 85: 'desert-rose', 99: 'bromelia', 87: 'magnolia', 5: 'english marigold', 92: 'bee balm', 28: 'stemless gentian', 97: 'mallow', 57: 'gaura', 40: 'lenten rose', 47: 'marigold', 59: 'orange dahlia', 48: 'buttercup', 55: 'pelargonium', 36: 'ruby-lipped cattleya', 91: 'hippeastrum', 29: 'artichoke', 71: 'gazania', 90: 'canna lily', 18: 'peruvian lily', 98: 'mexican petunia', 8: 'bird of paradise', 30: 'sweet william', 17: 'purple coneflower', 52: 'wild pansy', 84: 'columbine', 12: \"colt's foot\", 11: 'snapdragon', 96: 'camellia', 23: 'fritillary', 50: 'common dandelion', 44: 'poinsettia', 53: 'primula', 72: 'azalea', 65: 'californian poppy', 80: 'anthurium', 76: 'morning glory', 37: 'cape flower', 56: 'bishop of llandaff', 60: 'pink-yellow dahlia', 82: 'clematis', 58: 'geranium', 75: 'thorn apple', 41: 'barbeton daisy', 95: 'bougainvillea', 43: 'sword lily', 83: 'hibiscus', 78: 'lotus lotus', 88: 'cyclamen', 94: 'foxglove', 81: 'frangipani', 74: 'rose', 89: 'watercress', 73: 'water lily', 46: 'wallflower', 77: 'passion flower', 51: 'petunia'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ğŸ“ŠStep 5: Data Preprocessing and Augmentation\n",
        "Data augmentation helps in improving generalization and reducing overfitting. We apply several augmentations like rotation, zoom, horizontal flip, etc., to the training data. We only rescale the validation and test data to normalize the pixel values.\n",
        "\n"
      ],
      "metadata": {
        "id": "yTtOPt49B9qH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Data Preprocessing and Augmentation\n",
        "img_size = (224, 224)  # Resize all images to 224x224 pixels\n",
        "batch_size = 32\n",
        "\n",
        "# Data Augmentation for Training Data\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,  # Rescale image pixel values to [0, 1]\n",
        "    rotation_range=40,  # Random rotation from 0 to 40 degrees\n",
        "    width_shift_range=0.2,  # Random horizontal shift\n",
        "    height_shift_range=0.2,  # Random vertical shift\n",
        "    shear_range=0.2,  # Shear transformation\n",
        "    zoom_range=0.2,  # Random zoom\n",
        "    horizontal_flip=True,  # Random horizontal flip\n",
        "    fill_mode='nearest'  # Fill missing pixels after transformations\n",
        ")\n",
        "\n",
        "# Data Augmentation for Validation Data (only rescaling)\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Data Augmentation for Test Data (only rescaling)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Create Data Generators\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'  # Since this is a multi-class classification problem\n",
        ")\n",
        "\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    valid_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "HIOxOa0ECByn",
        "outputId": "7e706495-202e-4b47-98a0-c511e14d431a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 6552 images belonging to 102 classes.\n",
            "Found 818 images belonging to 102 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ğŸ§ Step 6: Build the CNN Model\n",
        "Now, we create a Convolutional Neural Network (CNN) for flower species classification. We include convolution layers for feature extraction, pooling layers for dimensionality reduction, and fully connected layers for classification. Additionally, we use different activation functions (ReLU, LeakyReLU, Softmax) and include dropout and L2 regularization to handle overfitting."
      ],
      "metadata": {
        "id": "mFzoQaVwChwL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Build the CNN Model\n",
        "num_classes = train_generator.num_classes  # Number of classes in the dataset\n",
        "\n",
        "model = models.Sequential([\n",
        "    # First Convolutional Block\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    # Second Convolutional Block\n",
        "    layers.Conv2D(64, (3, 3), activation=LeakyReLU(alpha=0.1)),\n",
        "    layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    # Third Convolutional Block\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    # Flatten Layer\n",
        "    layers.Flatten(),\n",
        "\n",
        "    # Fully Connected Layer with Dropout and L2 Regularization\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
        "\n",
        "    # Output Layer with Softmax activation for multi-class classification\n",
        "    layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Model summary to check the architecture\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "id": "i31du-eHCwCk",
        "outputId": "ff7318d3-15c1-47ef-d41a-b482da9b736d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m32\u001b[0m)   â”‚           \u001b[38;5;34m896\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m32\u001b[0m)   â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m64\u001b[0m)   â”‚        \u001b[38;5;34m18,496\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m64\u001b[0m)     â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m128\u001b[0m)    â”‚        \u001b[38;5;34m73,856\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m128\u001b[0m)    â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ flatten (\u001b[38;5;33mFlatten\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m86528\u001b[0m)          â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m86528\u001b[0m)          â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚    \u001b[38;5;34m44,302,848\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m102\u001b[0m)            â”‚        \u001b[38;5;34m52,326\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">86528</span>)          â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">86528</span>)          â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">44,302,848</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">102</span>)            â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">52,326</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m44,448,422\u001b[0m (169.56 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">44,448,422</span> (169.56 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m44,448,422\u001b[0m (169.56 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">44,448,422</span> (169.56 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 7: Compile the Model\n",
        "Now, we compile the model using categorical cross-entropy loss (since this is a multi-class classification problem) and an optimizer (Adam in this case).\n",
        "\n"
      ],
      "metadata": {
        "id": "LHTnlUaoC2pm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Compile the Model\n",
        "optimizer = Adam(learning_rate=0.001)  # Adam optimizer\n",
        "\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy',  # Multi-class cross-entropy loss\n",
        "    optimizer=optimizer,\n",
        "    metrics=['accuracy']  # Track accuracy during training\n",
        ")\n"
      ],
      "metadata": {
        "id": "pf6wXDL2C7R7"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 8: Define Callbacks\n",
        "Callbacks like ReduceLROnPlateau and EarlyStopping help with learning rate adjustment and stopping the training early if the model starts overfitting."
      ],
      "metadata": {
        "id": "ha4KK7YCDUZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_reduction = ReduceLROnPlateau(monitor='val_loss', patience=3, factor=0.5, verbose=1)\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n"
      ],
      "metadata": {
        "id": "sbB2grdNDXpl"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 9: Train the Model\n",
        "Now, we train the model on the training data and validate it on the validation set. We will also plot the training history to observe how the accuracy and loss evolve during the training."
      ],
      "metadata": {
        "id": "bMLg4Sx6Dbzl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=35,  # Set a reasonable number of epochs\n",
        "    validation_data=valid_generator,\n",
        "    callbacks=[early_stop, lr_reduction]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "64-h5IXrDeHg",
        "outputId": "e1ad72a9-0482-4041-e08f-11e30d470da2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/35\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 477ms/step - accuracy: 0.0671 - loss: 4.8646 - val_accuracy: 0.1687 - val_loss: 3.7406 - learning_rate: 0.0010\n",
            "Epoch 2/35\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 445ms/step - accuracy: 0.1866 - loss: 3.6943 - val_accuracy: 0.2311 - val_loss: 3.4661 - learning_rate: 0.0010\n",
            "Epoch 3/35\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 447ms/step - accuracy: 0.2347 - loss: 3.4928 - val_accuracy: 0.2689 - val_loss: 3.2850 - learning_rate: 0.0010\n",
            "Epoch 4/35\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 439ms/step - accuracy: 0.2927 - loss: 3.2875 - val_accuracy: 0.3203 - val_loss: 3.1730 - learning_rate: 0.0010\n",
            "Epoch 5/35\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 441ms/step - accuracy: 0.3388 - loss: 3.1416 - val_accuracy: 0.3900 - val_loss: 3.0726 - learning_rate: 0.0010\n",
            "Epoch 6/35\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 440ms/step - accuracy: 0.3420 - loss: 3.0908 - val_accuracy: 0.4046 - val_loss: 3.0071 - learning_rate: 0.0010\n",
            "Epoch 7/35\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 440ms/step - accuracy: 0.3702 - loss: 3.0118 - val_accuracy: 0.4279 - val_loss: 2.8581 - learning_rate: 0.0010\n",
            "Epoch 8/35\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 438ms/step - accuracy: 0.3941 - loss: 2.9640 - val_accuracy: 0.4511 - val_loss: 2.8174 - learning_rate: 0.0010\n",
            "Epoch 9/35\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 441ms/step - accuracy: 0.4149 - loss: 2.8816 - val_accuracy: 0.4450 - val_loss: 2.9616 - learning_rate: 0.0010\n",
            "Epoch 10/35\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 440ms/step - accuracy: 0.4446 - loss: 2.8501 - val_accuracy: 0.4645 - val_loss: 2.7768 - learning_rate: 0.0010\n",
            "Epoch 11/35\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 431ms/step - accuracy: 0.4581 - loss: 2.7639 - val_accuracy: 0.4389 - val_loss: 2.9379 - learning_rate: 0.0010\n",
            "Epoch 12/35\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 435ms/step - accuracy: 0.4407 - loss: 2.8040 - val_accuracy: 0.4768 - val_loss: 2.8146 - learning_rate: 0.0010\n",
            "Epoch 13/35\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419ms/step - accuracy: 0.4865 - loss: 2.7059\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 431ms/step - accuracy: 0.4865 - loss: 2.7060 - val_accuracy: 0.5061 - val_loss: 2.8268 - learning_rate: 0.0010\n",
            "Epoch 14/35\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 430ms/step - accuracy: 0.5060 - loss: 2.6001 - val_accuracy: 0.5685 - val_loss: 2.4191 - learning_rate: 5.0000e-04\n",
            "Epoch 15/35\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 432ms/step - accuracy: 0.5504 - loss: 2.3252 - val_accuracy: 0.5562 - val_loss: 2.5439 - learning_rate: 5.0000e-04\n",
            "Epoch 16/35\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 433ms/step - accuracy: 0.5717 - loss: 2.2350 - val_accuracy: 0.5709 - val_loss: 2.3611 - learning_rate: 5.0000e-04\n",
            "Epoch 17/35\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 435ms/step - accuracy: 0.5687 - loss: 2.2099 - val_accuracy: 0.5416 - val_loss: 2.4920 - learning_rate: 5.0000e-04\n",
            "Epoch 18/35\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 432ms/step - accuracy: 0.5822 - loss: 2.1444 - val_accuracy: 0.5489 - val_loss: 2.4457 - learning_rate: 5.0000e-04\n",
            "Epoch 19/35\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 435ms/step - accuracy: 0.5906 - loss: 2.1202 - val_accuracy: 0.5966 - val_loss: 2.2637 - learning_rate: 5.0000e-04\n",
            "Epoch 20/35\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 430ms/step - accuracy: 0.6061 - loss: 2.0591 - val_accuracy: 0.5770 - val_loss: 2.3480 - learning_rate: 5.0000e-04\n",
            "Epoch 21/35\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 430ms/step - accuracy: 0.6043 - loss: 2.0297 - val_accuracy: 0.6222 - val_loss: 2.1278 - learning_rate: 5.0000e-04\n",
            "Epoch 22/35\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 435ms/step - accuracy: 0.5943 - loss: 2.0605 - val_accuracy: 0.5685 - val_loss: 2.4035 - learning_rate: 5.0000e-04\n",
            "Epoch 23/35\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 435ms/step - accuracy: 0.6150 - loss: 1.9981 - val_accuracy: 0.5905 - val_loss: 2.3265 - learning_rate: 5.0000e-04\n",
            "Epoch 24/35\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423ms/step - accuracy: 0.6218 - loss: 1.9500\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 436ms/step - accuracy: 0.6217 - loss: 1.9503 - val_accuracy: 0.6015 - val_loss: 2.2441 - learning_rate: 5.0000e-04\n",
            "Epoch 25/35\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 430ms/step - accuracy: 0.6516 - loss: 1.8636 - val_accuracy: 0.6271 - val_loss: 2.1840 - learning_rate: 2.5000e-04\n",
            "Epoch 26/35\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 431ms/step - accuracy: 0.6654 - loss: 1.7749 - val_accuracy: 0.6222 - val_loss: 2.1395 - learning_rate: 2.5000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=valid_generator,\n",
        "    epochs=20,\n",
        "    callbacks=[early_stop, lr_reduction]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Nf9PJckOSORv",
        "outputId": "274673c0-f562-4a73-be4e-cb073c71b7ee"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 441ms/step - accuracy: 0.6248 - loss: 1.9219 - val_accuracy: 0.6381 - val_loss: 2.0432 - learning_rate: 2.5000e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 469ms/step - accuracy: 0.6472 - loss: 1.8276 - val_accuracy: 0.6112 - val_loss: 2.1416 - learning_rate: 2.5000e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 444ms/step - accuracy: 0.6651 - loss: 1.7527 - val_accuracy: 0.6320 - val_loss: 2.0052 - learning_rate: 2.5000e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 446ms/step - accuracy: 0.6622 - loss: 1.7187 - val_accuracy: 0.6394 - val_loss: 2.0015 - learning_rate: 2.5000e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 437ms/step - accuracy: 0.6633 - loss: 1.7229 - val_accuracy: 0.6296 - val_loss: 2.0123 - learning_rate: 2.5000e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 433ms/step - accuracy: 0.6799 - loss: 1.6464 - val_accuracy: 0.6222 - val_loss: 2.0135 - learning_rate: 2.5000e-04\n",
            "Epoch 7/20\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 439ms/step - accuracy: 0.6760 - loss: 1.6471 - val_accuracy: 0.6357 - val_loss: 1.9495 - learning_rate: 2.5000e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 438ms/step - accuracy: 0.6905 - loss: 1.5957 - val_accuracy: 0.6394 - val_loss: 1.9665 - learning_rate: 2.5000e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 441ms/step - accuracy: 0.6927 - loss: 1.5962 - val_accuracy: 0.6345 - val_loss: 1.9706 - learning_rate: 2.5000e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425ms/step - accuracy: 0.6856 - loss: 1.5636\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 435ms/step - accuracy: 0.6855 - loss: 1.5638 - val_accuracy: 0.6247 - val_loss: 2.0442 - learning_rate: 2.5000e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 449ms/step - accuracy: 0.7034 - loss: 1.5460 - val_accuracy: 0.6369 - val_loss: 1.9510 - learning_rate: 1.2500e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 441ms/step - accuracy: 0.7149 - loss: 1.4540 - val_accuracy: 0.6504 - val_loss: 1.8930 - learning_rate: 1.2500e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 433ms/step - accuracy: 0.7234 - loss: 1.4370 - val_accuracy: 0.6479 - val_loss: 1.8999 - learning_rate: 1.2500e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 441ms/step - accuracy: 0.7146 - loss: 1.4222 - val_accuracy: 0.6528 - val_loss: 1.9192 - learning_rate: 1.2500e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429ms/step - accuracy: 0.7284 - loss: 1.3897\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 440ms/step - accuracy: 0.7284 - loss: 1.3898 - val_accuracy: 0.6528 - val_loss: 1.9118 - learning_rate: 1.2500e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 444ms/step - accuracy: 0.7420 - loss: 1.3420 - val_accuracy: 0.6626 - val_loss: 1.8715 - learning_rate: 6.2500e-05\n",
            "Epoch 17/20\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 438ms/step - accuracy: 0.7356 - loss: 1.3289 - val_accuracy: 0.6577 - val_loss: 1.8734 - learning_rate: 6.2500e-05\n",
            "Epoch 18/20\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 436ms/step - accuracy: 0.7404 - loss: 1.3106 - val_accuracy: 0.6601 - val_loss: 1.8603 - learning_rate: 6.2500e-05\n",
            "Epoch 19/20\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 436ms/step - accuracy: 0.7385 - loss: 1.3123 - val_accuracy: 0.6577 - val_loss: 1.8721 - learning_rate: 6.2500e-05\n",
            "Epoch 20/20\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 456ms/step - accuracy: 0.7437 - loss: 1.2899 - val_accuracy: 0.6663 - val_loss: 1.8602 - learning_rate: 6.2500e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=valid_generator,\n",
        "    epochs=15,\n",
        "    callbacks=[early_stop, lr_reduction]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "bqXSSrH0ZVBK",
        "outputId": "cfdcbe15-1e2d-4b06-9b79-7dba525966b1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 440ms/step - accuracy: 0.7503 - loss: 1.2822 - val_accuracy: 0.6687 - val_loss: 1.8317 - learning_rate: 6.2500e-05\n",
            "Epoch 2/15\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 446ms/step - accuracy: 0.7474 - loss: 1.2905 - val_accuracy: 0.6687 - val_loss: 1.8325 - learning_rate: 6.2500e-05\n",
            "Epoch 3/15\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 435ms/step - accuracy: 0.7507 - loss: 1.2800 - val_accuracy: 0.6638 - val_loss: 1.8938 - learning_rate: 6.2500e-05\n",
            "Epoch 4/15\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419ms/step - accuracy: 0.7498 - loss: 1.2811\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 429ms/step - accuracy: 0.7498 - loss: 1.2810 - val_accuracy: 0.6601 - val_loss: 1.8627 - learning_rate: 6.2500e-05\n",
            "Epoch 5/15\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 436ms/step - accuracy: 0.7549 - loss: 1.2283 - val_accuracy: 0.6711 - val_loss: 1.8298 - learning_rate: 3.1250e-05\n",
            "Epoch 6/15\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 431ms/step - accuracy: 0.7687 - loss: 1.2003 - val_accuracy: 0.6711 - val_loss: 1.7817 - learning_rate: 3.1250e-05\n",
            "Epoch 7/15\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 436ms/step - accuracy: 0.7695 - loss: 1.2158 - val_accuracy: 0.6773 - val_loss: 1.7709 - learning_rate: 3.1250e-05\n",
            "Epoch 8/15\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 433ms/step - accuracy: 0.7624 - loss: 1.1779 - val_accuracy: 0.6748 - val_loss: 1.7905 - learning_rate: 3.1250e-05\n",
            "Epoch 9/15\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 437ms/step - accuracy: 0.7760 - loss: 1.1580 - val_accuracy: 0.6540 - val_loss: 1.8522 - learning_rate: 3.1250e-05\n",
            "Epoch 10/15\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - accuracy: 0.7683 - loss: 1.1875\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 430ms/step - accuracy: 0.7683 - loss: 1.1876 - val_accuracy: 0.6614 - val_loss: 1.8230 - learning_rate: 3.1250e-05\n",
            "Epoch 11/15\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 436ms/step - accuracy: 0.7833 - loss: 1.1533 - val_accuracy: 0.6675 - val_loss: 1.8316 - learning_rate: 1.5625e-05\n",
            "Epoch 12/15\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 441ms/step - accuracy: 0.7705 - loss: 1.1691 - val_accuracy: 0.6687 - val_loss: 1.8156 - learning_rate: 1.5625e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 10: Transfer Learning\n",
        "We'll use MobileNetV2 as the base model (you can change it to EfficientNet or others later if needed)."
      ],
      "metadata": {
        "id": "Nw5mB8w9fDij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load Pretrained Model (Transfer Learning)\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "\n",
        "# Load MobileNetV2 base model (without top layers)\n",
        "base_model = MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
        "base_model.trainable = False  # Freeze the base model\n",
        "\n",
        "#Add Custom Layers on Top\n",
        "x = base_model.output\n",
        "x = layers.GlobalAveragePooling2D()(x)  # Global pooling instead of flatten\n",
        "x = layers.Dropout(0.5)(x)\n",
        "x = layers.Dense(256, activation='relu')(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "output = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "# Final model\n",
        "model1 = Model(inputs=base_model.input, outputs=output)\n",
        "model1.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "collapsed": true,
        "id": "Nd1i_GiFe7_1",
        "outputId": "0a2089d8-0ab8-40df-c6d1-7f04d9d1591e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'num_classes' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-8268ab6f750f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Final model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'num_classes' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Compile the Model\n",
        "model1.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=Adam(learning_rate=0.0005),\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ],
      "metadata": {
        "id": "X4I69lmafc7B"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train the Model\n",
        "history1 = model1.fit(\n",
        "    train_generator,\n",
        "    epochs=30,\n",
        "    validation_data=valid_generator,\n",
        "    callbacks=[early_stop, lr_reduction]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "_lFVvtsTfjhM",
        "outputId": "434f85c9-5303-4042-ada4-095759c3e685"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 474ms/step - accuracy: 0.0762 - loss: 4.4902 - val_accuracy: 0.4743 - val_loss: 2.4610 - learning_rate: 5.0000e-04\n",
            "Epoch 2/30\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 432ms/step - accuracy: 0.3575 - loss: 2.7222 - val_accuracy: 0.6748 - val_loss: 1.4068 - learning_rate: 5.0000e-04\n",
            "Epoch 3/30\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 435ms/step - accuracy: 0.5035 - loss: 1.9272 - val_accuracy: 0.7457 - val_loss: 1.0219 - learning_rate: 5.0000e-04\n",
            "Epoch 4/30\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 433ms/step - accuracy: 0.5690 - loss: 1.5813 - val_accuracy: 0.7885 - val_loss: 0.8445 - learning_rate: 5.0000e-04\n",
            "Epoch 5/30\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 418ms/step - accuracy: 0.6039 - loss: 1.3726 - val_accuracy: 0.7922 - val_loss: 0.7643 - learning_rate: 5.0000e-04\n",
            "Epoch 6/30\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 422ms/step - accuracy: 0.6631 - loss: 1.2138 - val_accuracy: 0.8105 - val_loss: 0.6897 - learning_rate: 5.0000e-04\n",
            "Epoch 7/30\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 422ms/step - accuracy: 0.6875 - loss: 1.0998 - val_accuracy: 0.8252 - val_loss: 0.6542 - learning_rate: 5.0000e-04\n",
            "Epoch 8/30\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 424ms/step - accuracy: 0.6948 - loss: 1.0615 - val_accuracy: 0.8289 - val_loss: 0.6222 - learning_rate: 5.0000e-04\n",
            "Epoch 9/30\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 436ms/step - accuracy: 0.7068 - loss: 1.0318 - val_accuracy: 0.8447 - val_loss: 0.5736 - learning_rate: 5.0000e-04\n",
            "Epoch 10/30\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 431ms/step - accuracy: 0.7204 - loss: 0.9558 - val_accuracy: 0.8447 - val_loss: 0.5602 - learning_rate: 5.0000e-04\n",
            "Epoch 11/30\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 426ms/step - accuracy: 0.7446 - loss: 0.8903 - val_accuracy: 0.8509 - val_loss: 0.5279 - learning_rate: 5.0000e-04\n",
            "Epoch 12/30\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 422ms/step - accuracy: 0.7538 - loss: 0.8796 - val_accuracy: 0.8509 - val_loss: 0.5178 - learning_rate: 5.0000e-04\n",
            "Epoch 13/30\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 420ms/step - accuracy: 0.7510 - loss: 0.8576 - val_accuracy: 0.8545 - val_loss: 0.5040 - learning_rate: 5.0000e-04\n",
            "Epoch 14/30\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 415ms/step - accuracy: 0.7646 - loss: 0.8205 - val_accuracy: 0.8399 - val_loss: 0.5207 - learning_rate: 5.0000e-04\n",
            "Epoch 15/30\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 418ms/step - accuracy: 0.7673 - loss: 0.8039 - val_accuracy: 0.8594 - val_loss: 0.4848 - learning_rate: 5.0000e-04\n",
            "Epoch 16/30\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 420ms/step - accuracy: 0.7778 - loss: 0.7731 - val_accuracy: 0.8594 - val_loss: 0.4732 - learning_rate: 5.0000e-04\n",
            "Epoch 17/30\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 419ms/step - accuracy: 0.7749 - loss: 0.7396 - val_accuracy: 0.8533 - val_loss: 0.4951 - learning_rate: 5.0000e-04\n",
            "Epoch 18/30\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 422ms/step - accuracy: 0.7794 - loss: 0.7380 - val_accuracy: 0.8667 - val_loss: 0.4696 - learning_rate: 5.0000e-04\n",
            "Epoch 19/30\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 422ms/step - accuracy: 0.7850 - loss: 0.7290 - val_accuracy: 0.8619 - val_loss: 0.4809 - learning_rate: 5.0000e-04\n",
            "Epoch 20/30\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 426ms/step - accuracy: 0.7793 - loss: 0.7323 - val_accuracy: 0.8631 - val_loss: 0.4757 - learning_rate: 5.0000e-04\n",
            "Epoch 21/30\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - accuracy: 0.7906 - loss: 0.7077\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 427ms/step - accuracy: 0.7906 - loss: 0.7077 - val_accuracy: 0.8582 - val_loss: 0.4768 - learning_rate: 5.0000e-04\n",
            "Epoch 22/30\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 432ms/step - accuracy: 0.8036 - loss: 0.6697 - val_accuracy: 0.8631 - val_loss: 0.4544 - learning_rate: 2.5000e-04\n",
            "Epoch 23/30\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 418ms/step - accuracy: 0.7831 - loss: 0.7128 - val_accuracy: 0.8655 - val_loss: 0.4490 - learning_rate: 2.5000e-04\n",
            "Epoch 24/30\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 424ms/step - accuracy: 0.8075 - loss: 0.6567 - val_accuracy: 0.8667 - val_loss: 0.4458 - learning_rate: 2.5000e-04\n",
            "Epoch 25/30\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 421ms/step - accuracy: 0.8160 - loss: 0.6315 - val_accuracy: 0.8729 - val_loss: 0.4460 - learning_rate: 2.5000e-04\n",
            "Epoch 26/30\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 419ms/step - accuracy: 0.8067 - loss: 0.6456 - val_accuracy: 0.8716 - val_loss: 0.4443 - learning_rate: 2.5000e-04\n",
            "Epoch 27/30\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 424ms/step - accuracy: 0.8157 - loss: 0.6200 - val_accuracy: 0.8753 - val_loss: 0.4353 - learning_rate: 2.5000e-04\n",
            "Epoch 28/30\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 425ms/step - accuracy: 0.8142 - loss: 0.6006 - val_accuracy: 0.8716 - val_loss: 0.4221 - learning_rate: 2.5000e-04\n",
            "Epoch 29/30\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 421ms/step - accuracy: 0.8134 - loss: 0.6233 - val_accuracy: 0.8790 - val_loss: 0.4087 - learning_rate: 2.5000e-04\n",
            "Epoch 30/30\n",
            "\u001b[1m205/205\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 418ms/step - accuracy: 0.8188 - loss: 0.6139 - val_accuracy: 0.8814 - val_loss: 0.4122 - learning_rate: 2.5000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Fine tuning\n"
      ],
      "metadata": {
        "id": "WwXNwLHNst_u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Unfreeze the base model\n",
        "base_model.trainable = True\n",
        "\n",
        "# Freeze all layers except the last N (e.g., 20)\n",
        "fine_tune_at = len(base_model.layers) - 20\n",
        "\n",
        "for layer in base_model.layers[:fine_tune_at]:\n",
        "    layer.trainable = False\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "fhhUSqexsp_7",
        "outputId": "9ae9c56d-9803-42e2-eab9-d4056273ffec"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'base_model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1f60d7e46932>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Unfreeze the base model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Freeze all layers except the last N (e.g., 20)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfine_tune_at\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'base_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ğŸ“ˆStep 11: Plotting the Training and Validation Accuracy/Loss\n"
      ],
      "metadata": {
        "id": "VSdSpo7Ofy8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the Training and Validation Accuracy/Loss\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(14, 5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "jrGYjzOPDrEe",
        "outputId": "66dbb757-20ab-4354-bafb-7e4dd62c8da4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Figure size 1400x500 with 0 Axes>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1400x500 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### For CNN model"
      ],
      "metadata": {
        "id": "thwiS2Xfgkao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy Plot\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Accuracy Over Epochs')\n",
        "\n",
        "# Loss Plot\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.legend()\n",
        "plt.title('Loss Over Epochs')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "id": "us3sutl-DvFY",
        "outputId": "be40513a-6fb6-48a6-f298-e79517d7e387"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'history' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-08d73809face>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Accuracy Plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Train Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Validation Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### For pretrained model"
      ],
      "metadata": {
        "id": "tF08N32tgoIM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy Plot\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history1.history1['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history1.history1['val_accuracy'], label='Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Accuracy Over Epochs')\n",
        "\n",
        "# Loss Plot\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history1.history1['loss'], label='Train Loss')\n",
        "plt.plot(history1.history1['val_loss'], label='Validation Loss')\n",
        "plt.legend()\n",
        "plt.title('Loss Over Epochs')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "id": "GxWEzuQegR6L",
        "outputId": "fee1642a-91ec-415d-da65-7e09080a3625"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'history1' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-2a4a8076620f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Accuracy Plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Train Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Validation Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history1' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### âœ…Step 12: Prepare Test Predictions\n",
        "In this step, we load the test data and predict the flower species using the trained model. We also prepare the final submission file (flower_submission.csv)"
      ],
      "metadata": {
        "id": "RRP9fMJKSsZ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 9: Prepare Test Predictions\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "def preprocess_img(path):\n",
        "    img = image.load_img(path, target_size=img_size)\n",
        "    img = image.img_to_array(img) / 255.0\n",
        "    return img\n",
        "\n",
        "submission_csv_path = '/content/flower_dataset/sample_submission.csv'  # Path to sample_submission.csv file\n",
        "\n",
        "submission_df = pd.read_csv(submission_csv_path)  # Load sample_submission.csv\n",
        "test_image_paths = [os.path.join(test_dir, fname) for fname in submission_df['file_name']]\n",
        "test_images = np.array([preprocess_img(p) for p in test_image_paths])\n",
        "\n",
        "# Predict the test images\n",
        "preds = model.predict(test_images)\n",
        "\n",
        "# Convert predictions to flower ids and names\n",
        "pred_indices = np.argmax(preds, axis=1)  # Get the index with the highest probability\n",
        "\n",
        "# Map the indices back to flower ids\n",
        "index_to_class = {v: k for k, v in train_generator.class_indices.items()}\n",
        "submission_df['id'] = [index_to_class[idx] for idx in pred_indices]\n",
        "submission_df['flower_name'] = [cat_to_name.get(int(idx), \"Unknown\") for idx in pred_indices]\n",
        "\n",
        "# Save the submission file\n",
        "submission_df.to_csv('flower_submission.csv', index=False)\n",
        "submission_df.head()\n"
      ],
      "metadata": {
        "id": "6IVwvRFcSx5d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}